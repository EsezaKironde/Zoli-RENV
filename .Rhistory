geom_smooth(method = "loess", se = FALSE, color = "blue")
# Fit the logistic growth model using nls
logistic_nls <- nls(Population ~ K / (1 + ((K - N0)/N0) * exp(-r * Time)),
data = growth_data,
start = list(K = 100, r = 1, N0 = 10))
# Display the summary of the model
summary(logistic_nls)
# Generate fitted values
growth_data$Fitted <- predict(logistic_nls)
# Plot actual vs fitted values
ggplot(growth_data, aes(x = Time)) +
geom_point(aes(y = Population), color = "darkgreen", size = 3) +
geom_line(aes(y = Fitted), color = "red", size = 1) +
theme_minimal() +
labs(title = "Logistic Growth Model Fit",
x = "Time (hours)",
y = "Population")
# Set seed for reproducibility
set.seed(321)
# Generate sample data
n <- 200
age <- runif(n, min = 20, max = 70)  # Age in years
# Income increases with age up to 50, then plateaus
income <- ifelse(age <= 50,
2000 + 500 * age + rnorm(n, 0, 10000),
2000 + 500 * 50 + rnorm(n, 0, 10000)) +
0.02 * (age - 50)^2 * (age > 50)  # Slight decrease after 50
# Create a data frame
income_data <- data.frame(
Age = age,
Income = income
)
# Display first few rows
head(income_data)
# Load ggplot2 for visualization
library(ggplot2)
# Scatter plot with linear and polynomial fits
ggplot(income_data, aes(x = Age, y = Income)) +
geom_point(alpha = 0.6, color = "purple") +
geom_smooth(method = "lm", formula = y ~ x, color = "blue", se = FALSE, linetype = "dashed") +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", se = FALSE) +
theme_minimal() +
labs(title = "Income vs. Age with Linear and Polynomial Fits",
x = "Age (years)",
y = "Income ($)")
# Fit a simple linear regression model
linear_model <- lm(Income ~ Age, data = income_data)
# Fit a polynomial regression model (quadratic)
poly_model <- lm(Income ~ poly(Age, 2, raw = TRUE), data = income_data)
# Display summaries of both models
summary(linear_model)
summary(poly_model)
# Set seed for reproducibility
set.seed(654)
# Generate sample data
n <- 500
hours_studied <- runif(n, min = 0, max = 10)     # Hours studied
attendance_rate <- runif(n, min = 50, max = 100)  # Attendance rate in percentage
# Logistic function parameters
beta0 <- -5
beta1 <- 1.5
beta2 <- 0.05
# Calculate probability of passing
prob_pass <- 1 / (1 + exp(-(beta0 + beta1 * hours_studied + beta2 * attendance_rate)))
# Generate binary outcome
pass <- rbinom(n, size = 1, prob = prob_pass)
# Create a data frame
student_logistic <- data.frame(
Pass = factor(pass, levels = c(0,1), labels = c("Fail", "Pass")),
Hours_Studied = hours_studied,
Attendance_Rate = attendance_rate
)
# Display first few rows
head(student_logistic)
# Load ggplot2 for visualization
library(ggplot2)
# Scatter plot with Pass/Fail colored
ggplot(student_logistic, aes(x = Hours_Studied, y = Attendance_Rate, color = Pass)) +
geom_point(alpha = 0.6) +
theme_minimal() +
labs(title = "Exam Outcome Based on Study Hours and Attendance",
x = "Hours Studied",
y = "Attendance Rate (%)")
# Fit the logistic regression model
logistic_model <- glm(Pass ~ Hours_Studied + Attendance_Rate,
data = student_logistic,
family = binomial(link = "logit"))
# Display the summary of the model
summary(logistic_model)
# Predict probability of passing for a new student
new_student <- data.frame(Hours_Studied = 6, Attendance_Rate = 80)
predicted_prob <- predict(logistic_model, newdata = new_student, type = "response")
cat("Predicted Probability of Passing:", round(predicted_prob, 4), "\n")
# Set seed for reproducibility
set.seed(987)
# Generate sample data
n <- 100
education <- sample(12:20, n, replace = TRUE)           # Years of education
experience <- sample(0:40, n, replace = TRUE)          # Years of experience
age <- education + experience + rnorm(n, 0, 5)          # Age correlated with education and experience
gender <- factor(sample(c("Male", "Female"), n, replace = TRUE))
department <- factor(sample(c("HR", "Sales", "IT", "Marketing"), n, replace = TRUE))
performance_score <- runif(n, min = 1, max = 10)        # Performance score
# Assume salary is a function of the predictors
salary <- 30000 + 2000 * education + 1500 * experience +
500 * performance_score + rnorm(n, 0, 10000)
# Create a data frame
employee_data <- data.frame(
Salary = salary,
Education = education,
Experience = experience,
Age = age,
Gender = gender,
Department = department,
Performance_Score = performance_score
)
# Display first few rows
head(employee_data)
# Load necessary libraries
library(glmnet)
# Load necessary libraries
install.packages("glmnet")
library(glmnet)
library(caret)  # For data splitting
# Load necessary libraries
install.packages("glmnet")
install.packages("caret")
library(glmnet)
library(caret)  # For data splitting
# Encode categorical variables using dummy encoding
employee_dummy <- model.matrix(Salary ~ ., data = employee_data)[,-1]  # Remove intercept
# Response variable
y <- employee_data$Salary
# Split data into training and testing sets (70-30 split)
set.seed(123)
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
x_train <- employee_dummy[train_index, ]
x_test <- employee_dummy[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]
install.packages("glmnet")
# Set seed for reproducibility
set.seed(123)
# Fit Ridge Regression model (alpha = 0)
ridge_model <- cv.glmnet(x_train, y_train, alpha = 0, standardize = TRUE)
# Plot cross-validation results
plot(ridge_model)
title("Ridge Regression Cross-Validation", line = 2)
# Best lambda
best_lambda_ridge <- ridge_model$lambda.min
cat("Best Lambda for Ridge Regression:", best_lambda_ridge, "\n")
# Coefficients at best lambda
ridge_coef <- coef(ridge_model, s = "lambda.min")
print(ridge_coef)
# Set seed for reproducibility
set.seed(123)
# Fit Lasso Regression model (alpha = 1)
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, standardize = TRUE)
# Plot cross-validation results
plot(lasso_model)
title("Lasso Regression Cross-Validation", line = 2)
# Best lambda
best_lambda_lasso <- lasso_model$lambda.min
cat("Best Lambda for Lasso Regression:", best_lambda_lasso, "\n")
# Coefficients at best lambda
lasso_coef <- coef(lasso_model, s = "lambda.min")
print(lasso_coef)
# Predictions using Ridge Regression
ridge_pred <- predict(ridge_model, s = "lambda.min", newx = x_test)
# Predictions using Lasso Regression
lasso_pred <- predict(lasso_model, s = "lambda.min", newx = x_test)
# Calculate Mean Squared Error (MSE) for Ridge
mse_ridge <- mean((y_test - ridge_pred)^2)
cat("Ridge Regression MSE:", mse_ridge, "\n")
# Calculate Mean Squared Error (MSE) for Lasso
mse_lasso <- mean((y_test - lasso_pred)^2)
cat("Lasso Regression MSE:", mse_lasso, "\n")
# Plot residuals vs. fitted values for multiple linear regression
par(mfrow = c(2,2))  # Set plotting area
plot(multiple_lm)
# Perform Shapiro-Wilk test on residuals
shapiro_test <- shapiro.test(residuals(multiple_lm))
print(shapiro_test)
# Load car package for VIF
library(car)
# Load car package for VIF
install.packages("car")
library(car)
# Calculate VIF for multiple linear regression
vif_values <- vif(multiple_lm)
print(vif_values)
# Calculate condition indices
library(car)
vif_values <- vif(multiple_lm)
eigen_values <- eigen(cor(employee_dummy))$values
condition_indices <- sqrt(eigen_values[1]/eigen_values)
print(condition_indices)
# Compare AIC of linear and polynomial models
aic_linear <- AIC(linear_model)
aic_poly <- AIC(poly_model)
cat("AIC for Linear Model:", aic_linear, "\n")
cat("AIC for Polynomial Model:", aic_poly, "\n")
# Compare BIC of linear and polynomial models
bic_linear <- BIC(linear_model)
bic_poly <- BIC(poly_model)
cat("BIC for Linear Model:", bic_linear, "\n")
cat("BIC for Polynomial Model:", bic_poly, "\n")
# Set seed for reproducibility
set.seed(123)
# Number of subjects
n <- 30
# Create a data frame with subject IDs
subjects <- data.frame(Subject_ID = 1:n)
# Randomly assign to Group A or Group B
subjects$Group <- sample(c("A", "B"), size = n, replace = TRUE)
# Display the assignment
print(subjects)
# Set seed for reproducibility
set.seed(456)
# Number of subjects per group
n_per_group <- 15
# Create a data frame with replicated treatments
replicated_data <- data.frame(
Subject_ID = 1:(2 * n_per_group),
Group = rep(c("Control", "Treatment"), each = n_per_group)
)
# Display the data
print(replicated_data)
# Set seed for reproducibility
set.seed(789)
# Number of subjects
n <- 40
# Create a data frame with subject IDs and Gender
subjects_block <- data.frame(
Subject_ID = 1:n,
Gender = sample(c("Male", "Female"), size = n, replace = TRUE)
)
# Perform randomized assignment within each block (Gender)
subjects_block$Group <- NA
for(g in unique(subjects_block$Gender)){
indices <- which(subjects_block$Gender == g)
subjects_block$Group[indices] <- sample(c("A", "B"), size = length(indices), replace = TRUE)
}
# Display the assignment
print(head(subjects_block, 10))
# Set seed for reproducibility
set.seed(101)
# Number of subjects
n <- 30
# Define treatments
treatments <- c("T1", "T2", "T3")
# Randomly assign treatments
crd_data <- data.frame(
Subject_ID = 1:n,
Treatment = sample(treatments, size = n, replace = TRUE)
)
# Display the assignment
print(crd_data)
# Simulate response variable
set.seed(102)
crd_data$Response <- ifelse(crd_data$Treatment == "T1",
rnorm(n, mean = 50, sd = 10),
ifelse(crd_data$Treatment == "T2",
rnorm(n, mean = 55, sd = 10),
rnorm(n, mean = 60, sd = 10)))
# Fit One-Way ANOVA model
crd_aov <- aov(Response ~ Treatment, data = crd_data)
# Display ANOVA summary
summary(crd_aov)
# Set seed for reproducibility
set.seed(202)
# Number of blocks
blocks <- 10
# Treatments
treatments <- c("Control", "Treatment")
# Create a data frame with blocks
rbd_data <- data.frame(
Block = rep(1:blocks, each = 2),
Treatment = rep(treatments, times = blocks)
)
# Shuffle within blocks
rbd_data <- rbd_data[order(rbd_data$Block, sample(1:2, 2)), ]
# Set seed for reproducibility
set.seed(202)
# Number of blocks
blocks <- 10
# Treatments
treatments <- c("Control", "Treatment")
# Create a data frame with blocks
rbd_data <- data.frame(
Block = rep(1:blocks, each = 2),
Treatment = rep(treatments, times = blocks)
)
# Shuffle within blocks
rbd_data <- rbd_data[order(rbd_data$Block, sample(1:2, 2)), ]
# Set seed for reproducibility
set.seed(202)
# Number of blocks
blocks <- 10
# Treatments
treatments <- c("Control", "Treatment")
# Create a data frame with blocks
rbd_data <- data.frame(
Block = rep(1:blocks, each = 2),
Treatment = rep(treatments, times = blocks)
)
# Shuffle within blocks
rbd_data <- rbd_data[order(rbd_data$Block, sample(1:2, 2)), ]
# Fit Two-Way ANOVA model with Block as a factor
rbd_aov <- aov(Response ~ Treatment + Gender + Error(Block), data = rbd_data)
# Load necessary libraries
if(!require(car)){
install.packages("car")
library(car)
} else {
library(car)
}
# Set seed for reproducibility
set.seed(789)
# Number of subjects
n <- 40  # Must be divisible by number of blocks and treatments
# Define number of blocks and treatments
num_blocks <- 2  # e.g., Soil Type 1 and 2
num_treatments <- 2  # e.g., Fertilizer A and B
# Check if n is divisible by (num_blocks * num_treatments)
if(n %% (num_blocks * num_treatments) != 0){
stop("Number of subjects must be divisible by (number of blocks * number of treatments).")
}
# Create a data frame with subject IDs and Block
blocks <- rep(1:num_blocks, each = n / num_blocks)
subjects_block <- data.frame(
Subject_ID = 1:n,
Block = factor(blocks)
)
# Define treatments
treatments <- c("A", "B")
# Initialize Group column
subjects_block$Group <- NA
# Randomly assign treatments within each block
for(b in levels(subjects_block$Block)){
# Get indices for the current block
indices <- which(subjects_block$Block == b)
# Ensure equal assignment of treatments within blocks
# Number of subjects per treatment within a block
n_per_treatment <- length(indices) / num_treatments
# Assign treatments
subjects_block$Group[indices] <- sample(rep(treatments, each = n_per_treatment))
}
# Simulate response variable based on treatment and block
# Example: Treatment A has mean 50, Treatment B has mean 55
# Blocks may have an effect, e.g., Block 1 has mean +5
set.seed(790)  # Different seed for response
subjects_block$Response <- ifelse(subjects_block$Group == "A",
rnorm(n, mean = 50 + ifelse(subjects_block$Block == "1", 5, 0), sd = 10),
rnorm(n, mean = 55 + ifelse(subjects_block$Block == "1", 5, 0), sd = 10))
# Display the first few rows to verify
print(head(subjects_block, 10))
# Fit Two-Way ANOVA model with Block as a factor
rbd_aov <- aov(Response ~ Group + Block, data = subjects_block)
# Display ANOVA summary
summary(rbd_aov)
# Perform Post-hoc Analysis: Tukey's HSD
tukey_rbd <- TukeyHSD(rbd_aov)
print(tukey_rbd)
# Plot Tukey's HSD results
plot(tukey_rbd, las = 1)
# Diagnostic Plots
par(mfrow = c(2, 2))
plot(rbd_aov)
par(mfrow = c(1, 1))  # Reset plotting area
# Shapiro-Wilk Test for Normality of Residuals
shapiro_test_rbd <- shapiro.test(residuals(rbd_aov))
print(shapiro_test_rbd)
sessionInfo()
echo "hello world"
cat("hello from cat\n")
message("hello from message")
print("hello from print")
warning("hello from warning")
stop("hello from stop")
cat("hello from cat\n")
message("hello from message")
print("hello from print")
warning("hello from warning")
stop("hello from stop")
cat("hello from cat\n")
message("hello from message")
print("hello from print")
warning("hello from warning")
stop("hello from stop")
source("~/Downloads/data550/Mod2/test_script.R")
source("~/Downloads/data550/Mod2/test_script.R")
saveRDS(
random_numbers5,
file = here::here("output", "random_numbers5.rds")
)
make random_numbers
here::i_am(
"code/01_make_output.R"
)
set.seed(1)
random_numbers1 <- rnorm(100)
saveRDS(
random_numbers1,
file = here::here("output", "random_numbers1.rds")
)
set.seed(2)
random_numbers2 <- rgamma(100, shape = 1)
saveRDS(
random_numbers2,
file = here::here("output", "random_numbers2.rds")
)
set.seed(3)
random_numbers3 <- runif(100)
saveRDS(
random_numbers3,
file = here::here("output", "random_numbers3.rds")
)
set.seed(4)
random_numbers4 <- rbinom(100, 1, 0.25)
saveRDS(
random_numbers4,
file = here::here("output", "random_numbers4.rds")
)
set.seed(5)
random_numbers5 <- rgeom(100, 0.25)
saveRDS(
random_numbers5,
file = here::here("output", "random_numbers5.rds")
)
#| fig.cap = "Fifth set of random numbers"
hist(random_numbers5)
here::i_am(
"report.Rmd"
)
#! TO DO:
#!   read random_numbers1 from output directory
random_numbers1 <- readRDS(
here::here("output/random_numbers1.rds")
)
#! TO DO:
#!   read random_numbers2 from output directory
random_numbers2 <- readRDS(
here::here("output/random_numbers2.rds")
)
#! TO DO:
#!   read random_numbers3 from output directory
random_numbers3 <- readRDS(
here::here("output/random_numbers3.rds")
)
#! TO DO:
#!   read random_numbers4 from output directory
random_numbers4 <- readRDS(
here::here("output/random_numbers4.rds")
)
#| fig.cap = "First set of random numbers"
hist(random_numbers1)
#| fig.cap = "Second set of random numbers"
hist(random_numbers2)
#| fig.cap = "Third set of random numbers"
hist(random_numbers3)
#| fig.cap = "Fourth set of random numbers"
hist(random_numbers4)
#| fig.cap = "Fifth set of random numbers"
hist(random_numbers5)
here::i_am(
"code/01_make_output.R"
)
set.seed(1)
random_numbers1 <- rnorm(100)
saveRDS(
random_numbers1,
file = here::here("output", "random_numbers1.rds")
)
set.seed(2)
random_numbers2 <- rgamma(100, shape = 1)
saveRDS(
random_numbers2,
file = here::here("output", "random_numbers2.rds")
)
set.seed(3)
random_numbers3 <- runif(100)
saveRDS(
random_numbers3,
file = here::here("output", "random_numbers3.rds")
)
set.seed(4)
random_numbers4 <- rbinom(100, 1, 0.25)
saveRDS(
random_numbers4,
file = here::here("output", "random_numbers4.rds")
)
set.seed(5)
random_numbers5 <- rgeom(100, 0.25)
saveRDS(
random_numbers5,
file = here::here("output", "random_numbers5.rds")
)
getwd()
setwd("/Users/zolismith/Desktop/collaborating_using_renv")
renv::restore()
install.packages("wesanderson")
renv::restore()
renv::activate()
renv::restore()
renv::activate()
renv::restore()
getwd()
renv::restore()
install.packages("wesanderson")
install.packages("wesanderson")
getwd()
